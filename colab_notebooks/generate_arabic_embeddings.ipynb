{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Arabic Embeddings",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAKDS_dMWY50"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9fj_WFGWNwc"
      },
      "source": [
        "!pip install transformers\n",
        "!git clone https://github.com/aub-mind/arabert\n",
        "!pip install -r arabert/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1Ozy4P2W1rO"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7gZIaSWXFLP"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "from arabert.preprocess import ArabertPreprocessor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzYGeY10XkHz"
      },
      "source": [
        "# Initialize Model, Tokenizer and preprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbtcfd6gXrHu"
      },
      "source": [
        "Available models are:\n",
        "`aubmindlab/` +\n",
        "```\n",
        "bert-base-arabertv01\n",
        "bert-base-arabert\n",
        "bert-base-arabertv02\n",
        "bert-base-arabertv2\n",
        "bert-large-arabertv02\n",
        "bert-large-arabertv2\n",
        "araelectra-base-discriminator\n",
        "araelectra-base-generator\n",
        "aragpt2-base\n",
        "aragpt2-medium\n",
        "```\n",
        "\n",
        "for `aragpt2-large` and `mega`, you need to use:\n",
        "`from arabert.aragpt2.grover.modeling_gpt2 import GPT2LMHeadModel` instead of `AutoModel`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oviMhf4dWXul",
        "outputId": "faf63c0f-a72f-4e5f-b5ee-85e0724b4786"
      },
      "source": [
        "model_name = \"aubmindlab/bert-base-arabertv2\"\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-02-19 18:05:59,917 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OIF2Bgcaj37"
      },
      "source": [
        "Preprocessing the text before passing through the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojTDgJzAYTtN",
        "outputId": "4745fae1-8366-4c91-85a2-9abbae75eafe"
      },
      "source": [
        "text= \"شعرها جميل اليوم\"\n",
        "text_preprocessed = arabert_prep.preprocess(text)                                \n",
        "print(text)\n",
        "print(\"---------------------\")\n",
        "print(text_preprocessed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "شعرها جميل اليوم\n",
            "---------------------\n",
            "شعر +ها جميل ال+ يوم\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhE_4O34auQ8"
      },
      "source": [
        "Converting the text to tensors suitable for model input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vecNbxgqZHP8",
        "outputId": "f6d7e546-f9dc-4a95-9ca8-b298423623c2"
      },
      "source": [
        "#inputs is a dictionary containing inputs_ids, attention_masks and token_type_ids as pytorch tensors\n",
        "inputs = tokenizer.encode_plus(text_preprocessed, return_tensors='pt')\n",
        "print(inputs['input_ids'][0])\n",
        "print(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]))# some tokens might be split with ## by the tokenizer\n",
        "#AraGPT2 output will look gibberish because of encoding but don't worry about it"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  33, 2024,   10, 2243,   20,  437,   34])\n",
            "['[CLS]', 'شعر', '+ها', 'جميل', 'ال+', 'يوم', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp6oNsb2bWSb"
      },
      "source": [
        "Passing the input through the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-rwcUBsZ7yF"
      },
      "source": [
        "outputs = model(**inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6JlevjOaNN8",
        "outputId": "14fd09a5-0039-47b5-b5f4-485f4df6d61b"
      },
      "source": [
        "embeddings = outputs['last_hidden_state']\n",
        "embeddings.shape # batch_size x seq_len x emb_dim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 7, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nwq-qKKrdRBX",
        "outputId": "b01c74aa-79ef-486b-b75b-55ded53e6f28"
      },
      "source": [
        "embeddings_text_only = outputs['last_hidden_state'][0][1:-1] #without [CLS] and [SEP], only applicable in AraBERT and AraELECTRA\n",
        "embeddings_text_only.shape # (seq_len - 2) x emb_dim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju0noRXhaSaU",
        "outputId": "8a2382af-3d2a-47aa-cf33-3191bf918ac5"
      },
      "source": [
        "print(embeddings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.4212,  0.0906, -0.2257,  ..., -0.2509, -0.4637, -0.2456],\n",
            "         [ 0.1262, -0.1921,  0.3547,  ..., -0.0284,  0.0218,  0.8257],\n",
            "         [ 0.3750, -0.5048,  0.3407,  ..., -0.5022, -0.5551, -0.6074],\n",
            "         ...,\n",
            "         [-0.0807, -0.1237,  0.2332,  ..., -0.2287, -0.5295, -0.5163],\n",
            "         [ 0.2868, -0.4423,  0.1091,  ..., -0.0412, -0.3146, -0.1310],\n",
            "         [ 0.1527, -0.0043, -0.1426,  ..., -0.2322,  0.1667,  0.1843]]],\n",
            "       grad_fn=<NativeLayerNormBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS_OtDJIaAXq",
        "outputId": "c9e0c9eb-c8b6-4873-951a-2cd2b19d2767"
      },
      "source": [
        "# AraGPT2 and AraELECTRA does not have a pooler layer, you just take the embedding of the last token for AraGPT2, and the first for araElectra\n",
        "pooled_vector = outputs['pooler_output']\n",
        "pooled_vector.shape # batch_size x emb_dim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpiqUYFKceC8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
